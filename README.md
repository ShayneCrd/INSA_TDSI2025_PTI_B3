
# MS Brain Lesion Segmentation Benchmark (PTI Project)

## Introduction

This PTI project focuses on **3D brain lesion segmentation in Multiple Sclerosis (MS)**.
Several deep learning methods have been investigated, all showing different strengths depending on the evaluation metrics.

This project is built around **four specific datasets** that must be used for the pipeline to work as intended.  
However, it is also possible to experiment with **custom datasets**, provided they are available in **`.nii.gz` format** and converted to the **nnU-Net format**.

---

## Pre-requisites and Methods

This project compares three segmentation approaches:

- **LST-AI**  
  A state-of-the-art MS lesion segmentation tool using three pre-trained U-Nets.  
  Only **one-shot inference** is performed.

- **SegResNet (MONAI)**  
  A residual segmentation network implemented in the MONAI framework.

- **nnU-Net v2**  
  A self-configuring U-Net framework used both as a standalone segmentation method and as a **reference for cross-validation folds**.

---

## Important Notice

### Environment
For users with **ENS-Lyon accounts**, it is **mandatory** to use the `monai-dev` conda environment, which contains all required dependencies.

If you are **not on an ENS system**, follow this installation guide:  
ðŸ‘‰ https://www.creatis.insa-lyon.fr/~grenier/?p=409

### Pipeline dependency
This project strictly follows **nnU-Net conventions**:

- All datasets are converted to **nnU-Net format**
- **nnU-Net must be run first**
- **SegResNet cross-validation relies on folds generated by nnU-Net**

Running SegResNet **before nnU-Net** will lead to errors.

### LST-AI
LST-AI inference was performed on a **separate machine**, as it requires:
- HD-BET
- greedy registration tool
- a dedicated virtual environment

Official setup instructions are available here:  
ðŸ‘‰ https://github.com/CompImg/LST-AI

Scripts are provided to:
- run LST-AI inference
- convert predictions to **nnU-Net-compatible format**
- store them in `lstFrame/`

### Hardware
All experiments were conducted on an **RTX 3090 Ti (24 GB VRAM)**.

âš ï¸ Notes:
- RTX 4000 series may work
- RTX 5000 series (e.g. RTX 5090) caused **compatibility issues** with nnU-Net and SegResNet

---

## Step-by-step Execution Guide

first, start by cloning the repository on your machine:

```bash

git clone https://github.com/ShayneCrd/INSA_TDSI2025_PTI_B3.git

then deactivate the current conda environment for safety and activate monai-dev or you current working environment

conda deactivate
conda activate monai-dev  #or the name of your working environment

We then set the environment variables for nnUNet_raw, nnUNet_preprocessed, nnUNet_results. This is done to automate nnUNet:

```bash
vim ~/.bashrc

press on esc then i for insert mode
at the bottom, write:

```bash
export nnUNet_raw="/path/to/nnUnetFrame/nnUNet_raw"
export nnUNet_preprocessed="/path/to/nnUnetFrame/nnUNet_preprocessed"
export nnUNet_results="/path/to/nnUnetFrame/nnUNet_results"

press on esc then write :wq 

 
Move your un-formatted datasets into the nnUnetFrame directory. In our case: MSLesSeg, MICCAI2016_test, MICCAI2016_train, Open_ms_data-master

We will then convert each dataset into the nnUnet format and store them in the nnUNet_raw folder. In our project, we defined the new formatted names:

MSLesSeg = Dataset421_TDSI2025
MICCAI2016 = Dataset422_TDSI2025
Open_ms (longitudinal) = Dataset423_TDSI2025
Open_ms (cross-sectional) = Dataset424_TDSI2026

in your terminal:

cd path/to/nnUnetFrame

###Format Dataset 421:

--Later fix

###Format Dataset 422:

'''bash
python convert_MICCAI_to_nnUNet.py


if it doesn't work , check the paths at the top of the script: 
MICCAI_test_path, 
MICCAI_train_path, 
imagesTr_path
labelsTr_path 
imagesTs_path 
dataset_json_path 

Once the dataset422_TDSI has been created in nnUnet_raw, we have to fix the affines on the labels (an issue noticed using SegResNet). We basically resample all modalities based on one chosen modality. ref_mode 2 => each image is resampled in the flair space. --inplace overwrites the dataset_raw mentionned

```bash
python affine_fix422.py \
    --dataset_raw path/to/nnUNet_raw/Dataset422_TDSI2025 \
    --ref_mod 2 \ 
    --fix_labels
    --inplace


Format Dataset 423:
```bash
python Convert_OpenMS_to_nnUnet.py


Format Dataset 424:
```bash
python convert_openMS2_to_nnUnet.py
python fix_424_mismatch.py

then after 423 and 424 dataset have been formatted as detailed:
```bash
skullstrip_and_diff_423_424.py

The datasets conversion and pre-processing is done, we can now verify the datasets integrity using nnU-Net.
Anywhere in the project directory, run:

###For Dataset421: 
```bash
nnUNetv2_plan_and_preprocess -d 421 --verify_dataset_integrity"
###For Dataset422: 
```bash
nnUNetv2_plan_and_preprocess -d 422 --verify_dataset_integrity"
###For Dataset423: 
```bash
nnUNetv2_plan_and_preprocess -d 423 --verify_dataset_integrity"
###For Dataset424: 
```bash
nnUNetv2_plan_and_preprocess -d 424 --verify_dataset_integrity"

Once this step is done, we can perform nnUNet preprocessing.


